import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from datasets import load_dataset
#from flwr_datasets import FederatedDataset
from flwr_datasets.partitioner import VerticalSizePartitioner
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler

FEATURE_COLUMNS = [
    "HatchYear",
    "Type",
    "HatchQuarter", # client 1
    "Thinning",
    "EndFlockSize",
    "NumberOfHouses",  # client 2
    "FarmAvgAbAfterWk1",
    "VetAvgAbAfterWk1" # client 3
]

def _bin_houses(NumberOfHouses_series):
    bins = [-np.inf, 1.01, 2.01, 3.01, np.inf]
    labels = ["1", "2", "3", "morethan3"]
    return (
        pd.cut(NumberOfHouses_series, bins=bins, labels=labels, right=True)
        .astype(str)
        .replace("nan", "Unknown")
    )


def load_and_preprocess(
    dataframe: pd.DataFrame,
):
    """Preprocess a subset of the dataset columns into a purely
    numerical numpy array suitable for model training."""

    # Make a copy to avoid modifying the original
    X_df = dataframe.copy()

    # Identify which columns are present
    available_cols = set(X_df.columns)

    # ----------------------------------------------------------------------
    # FEATURE ENGINEERING ON NAME (if present)
    # ----------------------------------------------------------------------
    if "NumberOfHouses" in available_cols:
        X_df["NumberOfHouses"] = pd.to_numeric(X_df["NumberOfHouses"], errors="coerce")
        X_df["NumberOfHouses"] = _bin_houses(X_df["NumberOfHouses"])

    # ----------------------------------------------------------------------
    # IDENTIFY NUMERIC + CATEGORICAL COLUMNS
    # ----------------------------------------------------------------------
    categorical_cols = []
    if "NumberOfHouses" in X_df.columns:
        categorical_cols.append("NumberOfHouses")
    if "HatchQuarter" in X_df.columns:
        categorical_cols.append("HatchQuarter")
    if "Type" in X_df.columns:
        categorical_cols.append("Type")

    numeric_cols = [c for c in X_df.columns if c not in categorical_cols]

    # ----------------------------------------------------------------------
    # HANDLE MISSING VALUES
    # ----------------------------------------------------------------------
    if numeric_cols:
        X_df[numeric_cols] = X_df[numeric_cols].fillna(X_df[numeric_cols].median())

    # ----------------------------------------------------------------------
    # PREPROCESSOR (TRANSFORM TO PURE NUMERIC)
    # ----------------------------------------------------------------------
    transformers = []
    if numeric_cols:
        transformers.append(("num", StandardScaler(), numeric_cols))
    if categorical_cols:
        transformers.append(
            (
                "cat",
                OneHotEncoder(handle_unknown="ignore", sparse_output=False),
                categorical_cols,
            )
        )

    preprocessor = ColumnTransformer(transformers=transformers)

    # ----------------------------------------------------------------------
    # FIT TRANSFORMER & CONVERT TO NUMPY
    # ----------------------------------------------------------------------
    X_full = preprocessor.fit_transform(X_df)

    # Ensure output is always a dense numpy array
    if hasattr(X_full, "toarray"):
        X_full = X_full.toarray()

    return X_full.astype(np.float32)


fds = None  # Cache FederatedDataset


def load_data(partition_id: int, feature_splits: list[int]):
    dataset = load_dataset(
        "csv",
        data_files="C:/Users/4243692/flower-vfa-deployment/vertical-fl-own/data/train.csv",
        split="train"
    )

    # remove free range and organic (BEFORE creating clients)
    dataset = dataset.filter(
        lambda x: x["Type"] != "free range and organic"
    )

    dataset = dataset.remove_columns(["FarmIdentification", "VetId"])

    partitioner = VerticalSizePartitioner(
        partition_sizes=feature_splits,
        active_party_columns="AntibioticsAfterWeek1",
        active_party_columns_mode="create_as_last",
    )

    partitioner.dataset = dataset

    partition = partitioner.load_partition(partition_id)

    return load_and_preprocess(dataframe=partition.to_pandas())


class ClientModel(nn.Module):
    def __init__(self, input_size, out_feat_dim):
        super().__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.fc2 = nn.Linear(128, out_feat_dim)

    def forward(self, x):
        x = self.fc1(x)
        x = nn.functional.relu(x)
        return self.fc2(x)


class ServerModel(nn.Module):
    def __init__(self, input_size):
        super(ServerModel, self).__init__()
        self.hidden = nn.Linear(input_size, 96)
        self.fc = nn.Linear(96, 1)
        self.bn = nn.BatchNorm1d(96)
        #self.sigmoid = nn.Sigmoid()     # removed because I changed to BCEWithLogitsLoss

    def forward(self, x):
        x = self.hidden(x)
        x = nn.functional.relu(x)
        x = self.bn(x)
        x = self.fc(x)
        #return self.sigmoid(x)
        return x


def evaluate_head_model(
    head: ServerModel, embeddings: torch.Tensor, labels: torch.Tensor
) -> float:
    """Compute accuracy of head."""
    head.eval()
    with torch.no_grad():
        correct = 0
        # Re-compute embeddings for accuracy (detached from grad)
        embeddings_eval = embeddings.detach()
        output = head(embeddings_eval)
        probs = torch.sigmoid(output)       # only if not using sigmoid function in forward pass
        predicted = (probs > 0.5).float()
        correct += (predicted == labels).sum().item()
        accuracy = correct / len(labels) * 100

        TP = ((predicted == 1) & (labels == 1)).sum().item()
        FN = ((predicted == 0) & (labels == 1)).sum().item()
        FP = ((predicted == 1) & (labels == 0)).sum().item()
        TN = ((predicted == 0) & (labels == 0)).sum().item()
        sensitivity = (TP / (TP + FN))*100 if (TP + FN) > 0 else 0.0
        specificity = (TN / (TN + FP))*100 if (TP + FN) > 0 else 0.0

    return accuracy, sensitivity, specificity
